name: Human Test Metrics v5

on:
  workflow_dispatch:
    inputs:
      repo:
        description: "Repository (e.g. owner/name)"
        required: true
        type: string
      pr_number:
        description: "Pull request number"
        required: true
        type: string
      language:
        description: "Project language"
        required: true
        type: choice
        options:
          - python
          - cpp
          - java
          - kotlin
          - go

jobs:
  test-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.inputs.repo }}
          ref: refs/pull/${{ github.event.inputs.pr_number }}/head
          fetch-depth: 0

      - name: Setup Python for parsing (always needed)
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install parsing dependencies
        run: |
          pip install lxml beautifulsoup4 pandas

      # =======================
      # Python Configuration
      # =======================
      - name: Setup Python Project
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          # Install Python project dependencies
          pip install --upgrade pip wheel setuptools
          
          # Try multiple ways to install project dependencies
          echo "=== Installing project dependencies ==="
          
          # Check for various dependency files
          if [ -f "requirements.txt" ]; then
            echo "Found requirements.txt"
            pip install -r requirements.txt
          fi
          
          if [ -f "requirements-dev.txt" ]; then
            echo "Found requirements-dev.txt"
            pip install -r requirements-dev.txt
          fi
          
          if [ -f "requirements/dev.txt" ]; then
            echo "Found requirements/dev.txt"
            pip install -r requirements/dev.txt
          fi
          
          if [ -f "requirements/test.txt" ]; then
            echo "Found requirements/test.txt"
            pip install -r requirements/test.txt
          fi
          
          if [ -f "setup.py" ]; then
            echo "Found setup.py"
            pip install -e ".[test]" 2>/dev/null || pip install -e ".[tests]" 2>/dev/null || pip install -e . 2>/dev/null || true
          fi
          
          if [ -f "pyproject.toml" ]; then
            echo "Found pyproject.toml"
            # Check if it's a poetry project
            if grep -q "tool.poetry" pyproject.toml; then
              pip install poetry
              poetry install --with test 2>/dev/null || poetry install 2>/dev/null || true
            else
              pip install -e ".[test]" 2>/dev/null || pip install -e ".[tests]" 2>/dev/null || pip install -e . 2>/dev/null || true
            fi
          fi
          
          if [ -f "Pipfile" ]; then
            echo "Found Pipfile"
            pip install pipenv
            pipenv install --dev --deploy --system 2>/dev/null || pipenv install --system 2>/dev/null || true
          fi
          
          # Install comprehensive testing tools
          pip install pytest pytest-cov pytest-xdist pytest-timeout pytest-mock coverage[toml] mutmut
          pip install flake8 flake8-pytest-style flake8-test-name flake8-aaa flake8-assertive
          pip install pylint radon mccabe
          pip install hypothesis pytest-benchmark pytest-sugar

      - name: Configure Python testing environment
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          # Create comprehensive coverage configuration
          cat > .coveragerc <<'EOF'
          [run]
          branch = True
          source = .
          omit = 
              */tests/*
              */test/*
              */__pycache__/*
              */venv/*
              */env/*
              */.venv/*
              */setup.py
              */conf.py
              */docs/*
              */migrations/*
          parallel = True
          
          [report]
          precision = 2
          show_missing = True
          skip_covered = False
          
          [xml]
          output = coverage.xml
          EOF
          
          # Create pytest configuration if not exists
          if [ ! -f "pytest.ini" ] && [ ! -f "setup.cfg" ] && [ ! -f "pyproject.toml" ]; then
            cat > pytest.ini <<'EOF'
          [tool:pytest]
          testpaths = tests test testing
          python_files = test_*.py *_test.py *tests.py
          python_classes = Test* *Tests *Test
          python_functions = test_*
          addopts = 
              -ra
              --strict-markers
              --cov=.
              --cov-branch
              --cov-report=term-missing:skip-covered
              --cov-report=xml
              --cov-report=html
              --tb=short
              -v
          EOF
          fi

      - name: Discover Python project structure
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          echo "=== Python Project Structure ==="
          
          # Find main source directories
          echo "Source directories:"
          find . -type f -name "*.py" -not -path "*/test*" -not -path "*/.*" | head -20
          
          # Find test directories
          echo -e "\nTest directories:"
          find . -type d \( -name "test*" -o -name "*test" -o -name "*tests" \) -not -path "*/.*" | head -10
          
          # Find test files
          echo -e "\nTest files:"
          find . -type f -name "*test*.py" -not -path "*/.*" | head -20
          
          # Identify main package
          echo -e "\nMain packages:"
          find . -maxdepth 2 -type f -name "__init__.py" -not -path "*/test*" -not -path "*/.*" | xargs -r dirname | sort -u
          
          # Store information for later use
          MAIN_PACKAGE=$(find . -maxdepth 2 -type f -name "__init__.py" -not -path "*/test*" -not -path "*/.*" | head -1 | xargs -r dirname)
          echo "MAIN_PACKAGE=${MAIN_PACKAGE}" >> $GITHUB_ENV

      - name: Run Python tests with comprehensive coverage
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set +e
          
          # Find test directories and files
          TEST_PATHS=""
          for dir in tests test testing test_suite; do
            if [ -d "$dir" ]; then
              TEST_PATHS="$TEST_PATHS $dir"
            fi
          done
          
          # If no test directories, find test files
          if [ -z "$TEST_PATHS" ]; then
            TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" | grep -v __pycache__ | grep -v ".venv" | head -50)
            if [ -n "$TEST_FILES" ]; then
              TEST_PATHS="."
            fi
          fi
          
          echo "Test paths: $TEST_PATHS"
          
          # Run tests with coverage
          if [ -n "$TEST_PATHS" ]; then
            # Clear any previous coverage data
            coverage erase 2>/dev/null || true
            
            # Run pytest with coverage
            python -m pytest $TEST_PATHS \
              --cov=. \
              --cov-branch \
              --cov-report=xml:coverage.xml \
              --cov-report=html:htmlcov \
              --cov-report=term-missing \
              --cov-report=json:coverage.json \
              --junit-xml=pytest-report.xml \
              --timeout=300 \
              -v \
              --tb=short 2>&1 | tee pytest_output.txt
            
            TEST_EXIT_CODE=${PIPESTATUS[0]}
            
            # Also try coverage run as backup
            if [ ! -f "coverage.xml" ] || [ $TEST_EXIT_CODE -ne 0 ]; then
              coverage run -m pytest $TEST_PATHS 2>&1 | tee coverage_run_output.txt
              coverage xml -o coverage.xml
              coverage json -o coverage.json
              coverage html -d htmlcov
              coverage report | tee coverage_report.txt
            fi
          else
            echo "No tests found" | tee pytest_output.txt
            TEST_EXIT_CODE=1
          fi
          
          if [ $TEST_EXIT_CODE -ne 0 ]; then
            echo "TESTS_FAILED" > test_fail.txt
          fi
          
          # Display coverage report
          if [ -f "coverage.xml" ]; then
            echo -e "\n=== Coverage Summary ==="
            python -c "
          import xml.etree.ElementTree as ET
          tree = ET.parse('coverage.xml')
          root = tree.getroot()
          print(f\"Line Coverage: {float(root.attrib.get('line-rate', 0)) * 100:.2f}%\")
          print(f\"Branch Coverage: {float(root.attrib.get('branch-rate', 0)) * 100:.2f}%\")
          "
          fi

     
      - name: Run Python mutation testing with mutmut
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set +e
          
          # Configure mutmut
          echo "=== Configuring mutmut ==="
          
          # Find source paths to mutate (exclude tests)
          SOURCE_PATHS=$(find . -name "*.py" -not -path "*/test*" -not -path "*/.*" -not -path "*/venv/*" -not -path "*/env/*" | head -50 | xargs -r dirname | sort -u | head -5)
          
          if [ -z "$SOURCE_PATHS" ]; then
            SOURCE_PATHS="."
          fi
          
          echo "Source paths to mutate: $SOURCE_PATHS"
          
          # Create mutmut config
          cat > .mutmut.cfg <<EOF
          [mutmut]
          paths_to_mutate=$SOURCE_PATHS
          tests_dir=.
          dict_synonyms=False
          EOF
          
          # Run mutation testing
          echo "=== Running mutation testing ==="
          
          # Initialize mutmut cache
          rm -f .mutmut-cache 2>/dev/null || true
          
          # Run mutmut with timeout per mutant
          for path in $SOURCE_PATHS; do
            echo "Mutating path: $path"
            timeout 1800 mutmut run \
              --paths-to-mutate="$path" \
              --runner="python -m pytest -x -q" \
              --use-coverage \
              --simple-output \
              2>&1 | tee -a mutmut_output.txt || true
          done
          
          # Check if mutation testing succeeded
          if [ -f ".mutmut-cache" ]; then
            echo -e "\n=== Mutation Testing Results ==="
            mutmut results 2>&1 | tee mutations.txt || true
            mutmut show all 2>&1 | tee mutations_detailed.txt || true
            mutmut html 2>/dev/null || true
            
            # Extract mutation score
            python -c "
          import sqlite3
          try:
              conn = sqlite3.connect('.mutmut-cache')
              cursor = conn.cursor()
              cursor.execute('SELECT status, COUNT(*) FROM mutant GROUP BY status')
              results = dict(cursor.fetchall())
              killed = results.get('killed', 0)
              survived = results.get('survived', 0)
              timeout = results.get('timeout', 0)
              total = killed + survived + timeout
              if total > 0:
                  score = (killed / total) * 100
                  print(f'Mutation Score: {score:.2f}%')
                  print(f'Killed: {killed}, Survived: {survived}, Timeout: {timeout}')
              conn.close()
          except Exception as e:
              print(f'Error reading mutation results: {e}')
          " | tee mutation_score.txt
          else
            echo "MUTATION_FAILED" > mutation_fail.txt
          fi


      - name: Detect Python test smells
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          echo "=== Detecting Test Smells ==="
          
          # Initialize smell counter
          TOTAL_SMELLS=0
          
          # Find test files
          TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" | grep -v __pycache__ | grep -v ".venv")
          
          # 1. Flake8 test smells
          echo "Running flake8 for test smells..."
          flake8 --select=PT,AAA,T $TEST_FILES --exit-zero > flake8_smells.txt 2>&1 || true
          FLAKE8_COUNT=$(wc -l < flake8_smells.txt)
          TOTAL_SMELLS=$((TOTAL_SMELLS + FLAKE8_COUNT))
          
          # 2. Custom smell detection
          python3 <<'PYTHON_SMELL_DETECTOR'
          import os
          import ast
          import re
          from pathlib import Path
          
          test_files = []
          for pattern in ["*test*.py", "test_*.py"]:
              test_files.extend(Path(".").rglob(pattern))
          
          smells = []
          
          for file_path in test_files:
              if ".venv" in str(file_path) or "__pycache__" in str(file_path):
                  continue
                  
              try:
                  with open(file_path, 'r', encoding='utf-8') as f:
                      content = f.read()
                      tree = ast.parse(content)
                  
                  # Detect various test smells
                  for node in ast.walk(tree):
                      # 1. Empty tests
                      if isinstance(node, ast.FunctionDef) and node.name.startswith("test"):
                          if len(node.body) == 1 and isinstance(node.body[0], ast.Pass):
                              smells.append(f"{file_path}:{node.lineno}: Empty test")
                          
                          # 2. Tests without assertions
                          has_assert = any(isinstance(n, ast.Assert) for n in ast.walk(node))
                          has_assert_call = any(
                              isinstance(n, ast.Call) and 
                              isinstance(n.func, ast.Attribute) and 
                              n.func.attr.startswith('assert')
                              for n in ast.walk(node)
                          )
                          if not has_assert and not has_assert_call and len(node.body) > 1:
                              smells.append(f"{file_path}:{node.lineno}: Test without assertion")
                          
                          # 3. Too many assertions (>5)
                          assertion_count = sum(1 for n in ast.walk(node) if isinstance(n, ast.Assert))
                          if assertion_count > 5:
                              smells.append(f"{file_path}:{node.lineno}: Too many assertions ({assertion_count})")
                  
                  # 4. TODO/FIXME in tests
                  for i, line in enumerate(content.split('\n'), 1):
                      if 'TODO' in line or 'FIXME' in line:
                          smells.append(f"{file_path}:{i}: TODO/FIXME comment")
                  
                  # 5. Hardcoded test data
                  hardcoded_patterns = [
                      r'127\.0\.0\.1',
                      r'localhost:?\d+',
                      r'password\s*=\s*["\'].*["\']',
                      r'/tmp/test',
                      r'C:\\\\test'
                  ]
                  for pattern in hardcoded_patterns:
                      matches = re.finditer(pattern, content, re.IGNORECASE)
                      for match in matches:
                          line_no = content[:match.start()].count('\n') + 1
                          smells.append(f"{file_path}:{line_no}: Hardcoded test data")
                  
              except Exception as e:
                  print(f"Error processing {file_path}: {e}")
          
          # Write smells to file
          with open("custom_smells.txt", "w") as f:
              for smell in smells:
                  f.write(smell + "\n")
          
          print(f"Found {len(smells)} custom test smells")
          PYTHON_SMELL_DETECTOR
          
          CUSTOM_COUNT=$(wc -l < custom_smells.txt 2>/dev/null || echo 0)
          TOTAL_SMELLS=$((TOTAL_SMELLS + CUSTOM_COUNT))
          
          # 3. Cyclomatic complexity in tests
          echo "Checking cyclomatic complexity in tests..."
          radon cc $TEST_FILES -s -n B 2>/dev/null | grep -E "^\s+F|^\s+C|^\s+D" > complex_tests.txt || true
          COMPLEX_COUNT=$(wc -l < complex_tests.txt 2>/dev/null || echo 0)
          TOTAL_SMELLS=$((TOTAL_SMELLS + COMPLEX_COUNT))
          
          # Save total count
          echo $TOTAL_SMELLS > test_smells.txt
          echo "Total test smells found: $TOTAL_SMELLS"

      # =======================
      # C++ Configuration
      # =======================
      - name: Install C++ tools
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            cmake \
            ninja-build \
            lcov \
            gcovr \
            clang \
            clang-tidy \
            cppcheck \
            llvm \
            libgtest-dev \
            libgmock-dev \
            catch2
          
          # Build Google Test
          cd /usr/src/gtest
          sudo cmake CMakeLists.txt
          sudo make
          sudo cp lib/*.a /usr/lib || sudo cp *.a /usr/lib
          
          # Install mutation testing tool
          git clone https://github.com/nlohmann/mutate_cpp.git /tmp/mutate_cpp 2>/dev/null || true

      - name: Build and test C++ with comprehensive coverage
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          set +e
          
          # Find build system
          BUILD_SYSTEM=""
          if [ -f "CMakeLists.txt" ]; then
            BUILD_SYSTEM="cmake"
          elif [ -f "Makefile" ]; then
            BUILD_SYSTEM="make"
          elif [ -f "meson.build" ]; then
            BUILD_SYSTEM="meson"
          fi
          
          echo "Build system: $BUILD_SYSTEM"
          
          if [ "$BUILD_SYSTEM" = "cmake" ]; then
            # CMake build
            mkdir -p build && cd build
            
            cmake .. \
              -DCMAKE_BUILD_TYPE=Debug \
              -DCMAKE_CXX_FLAGS="--coverage -g -O0 -fprofile-arcs -ftest-coverage -fPIC" \
              -DCMAKE_C_FLAGS="--coverage -g -O0 -fprofile-arcs -ftest-coverage -fPIC" \
              -DCMAKE_EXE_LINKER_FLAGS="--coverage -lgcov" \
              -DCMAKE_EXPORT_COMPILE_COMMANDS=ON \
              2>&1 | tee cmake_output.txt
            
            if [ $? -ne 0 ]; then
              echo "BUILD_FAILED" > ../build_fail.txt
              cd ..
              exit 0
            fi
            
            # Build
            make -j$(nproc) VERBOSE=1 2>&1 | tee make_output.txt
            if [ $? -ne 0 ]; then
              echo "BUILD_FAILED" > ../build_fail.txt
              cd ..
              exit 0
            fi
            
            # Run tests
            ctest --output-on-failure -V 2>&1 | tee ctest_output.txt
            TEST_EXIT=$?
            
            # Generate coverage
            cd ..
            lcov --capture --directory . --output-file coverage.info 2>/dev/null || true
            lcov --remove coverage.info '/usr/*' '*/test/*' --output-file coverage.info 2>/dev/null || true
            genhtml coverage.info --output-directory coverage_html 2>/dev/null || true
            
            # Also use gcovr for XML output
            gcovr -r . \
              --xml -o coverage.xml \
              --html-details -o coverage.html \
              --exclude-directories test \
              --exclude-directories tests \
              --print-summary 2>&1 | tee gcovr_output.txt || true
              
          elif [ "$BUILD_SYSTEM" = "make" ]; then
            # Makefile build
            make clean 2>/dev/null || true
            make CXXFLAGS="--coverage -g -O0" LDFLAGS="--coverage" all 2>&1 | tee make_output.txt
            if [ $? -ne 0 ]; then
              echo "BUILD_FAILED" > build_fail.txt
              exit 0
            fi
            
            # Run tests
            make test 2>&1 | tee test_output.txt || ./test 2>&1 | tee test_output.txt || true
            TEST_EXIT=$?
            
            # Generate coverage
            gcovr -r . --xml -o coverage.xml --html -o coverage.html 2>/dev/null || true
          fi
          
          if [ $TEST_EXIT -ne 0 ]; then
            echo "TESTS_FAILED" > test_fail.txt
          fi

      - name: Run C++ mutation testing
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          set +e
          
          # Simple mutation testing using sed
          echo "=== Running mutation testing ==="
          
          python3 <<'CPP_MUTATOR'
          import os
          import re
          import subprocess
          import json
          
          mutations = []
          source_files = []
          
          # Find source files
          for root, dirs, files in os.walk('.'):
              if 'test' in root or 'build' in root:
                  continue
              for file in files:
                  if file.endswith(('.cpp', '.cc', '.cxx')) and not file.endswith('_test.cpp'):
                      source_files.append(os.path.join(root, file))
          
          # Define mutation operators
          operators = [
              (r'==', '!=', 'Equality to Inequality'),
              (r'!=', '==', 'Inequality to Equality'),
              (r'<', '<=', 'Less Than to Less Equal'),
              (r'>', '>=', 'Greater Than to Greater Equal'),
              (r'\+\+', '--', 'Increment to Decrement'),
              (r'--', '++', 'Decrement to Increment'),
              (r'&&', '||', 'AND to OR'),
              (r'\|\|', '&&', 'OR to AND'),
              (r'true', 'false', 'True to False'),
              (r'false', 'true', 'False to True'),
          ]
          
          killed = 0
          survived = 0
          
          for source_file in source_files[:10]:  # Limit to 10 files for time
              with open(source_file, 'r') as f:
                  original_content = f.read()
              
              for pattern, replacement, description in operators:
                  matches = list(re.finditer(pattern, original_content))
                  
                  for match in matches[:5]:  # Limit mutations per operator
                      # Create mutant
                      mutated = original_content[:match.start()] + replacement + original_content[match.end():]
                      
                      # Write mutant
                      with open(source_file, 'w') as f:
                          f.write(mutated)
                      
                      # Try to compile and test
                      compile_result = subprocess.run(['make', '-C', 'build'], capture_output=True, timeout=30)
                      
                      if compile_result.returncode == 0:
                          test_result = subprocess.run(['ctest', '--test-dir', 'build'], capture_output=True, timeout=30)
                          
                          if test_result.returncode != 0:
                              killed += 1
                              status = 'killed'
                          else:
                              survived += 1
                              status = 'survived'
                      else:
                          killed += 1  # Compilation failure counts as killed
                          status = 'killed'
                      
                      mutations.append({
                          'file': source_file,
                          'line': original_content[:match.start()].count('\n') + 1,
                          'operator': description,
                          'status': status
                      })
                      
                      # Restore original
                      with open(source_file, 'w') as f:
                          f.write(original_content)
          
          # Save results
          with open('mutations.json', 'w') as f:
              json.dump({'mutants': mutations, 'summary': {'killed': killed, 'survived': survived}}, f, indent=2)
          
          if killed + survived > 0:
              score = (killed / (killed + survived)) * 100
              print(f"Mutation Score: {score:.2f}% ({killed} killed, {survived} survived)")
          CPP_MUTATOR

      - name: Detect C++ test smells
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          echo "=== Detecting C++ Test Smells ==="
          
          TOTAL_SMELLS=0
          
          # Find test files
          TEST_FILES=$(find . -name "*test*.cpp" -o -name "*test*.cc" -o -name "*_test.cpp" | grep -v build)
          
          # Run cppcheck on tests
          cppcheck --enable=all --suppress=missingIncludeSystem $TEST_FILES 2> cppcheck_smells.txt || true
          CPPCHECK_COUNT=$(grep -c "error\|warning\|style" cppcheck_smells.txt 2>/dev/null || echo 0)
          TOTAL_SMELLS=$((TOTAL_SMELLS + CPPCHECK_COUNT))
          
          # Custom smell detection
          for file in $TEST_FILES; do
            # Empty tests
            grep -n "TEST.*{[[:space:]]*}" "$file" >> empty_tests.txt 2>/dev/null || true
            
            # Tests without assertions
            awk '/TEST.*{/,/^}/' "$file" | grep -L "EXPECT\|ASSERT\|CHECK\|REQUIRE" >> no_assert.txt 2>/dev/null || true
            
            # TODO/FIXME
            grep -n "TODO\|FIXME" "$file" >> todo_tests.txt 2>/dev/null || true
            
            # Magic numbers
            grep -n "[^0-9][0-9]\{3,\}[^0-9]" "$file" >> magic_numbers.txt 2>/dev/null || true
          done
          
          CUSTOM_COUNT=$(cat empty_tests.txt no_assert.txt todo_tests.txt magic_numbers.txt 2>/dev/null | wc -l)
          TOTAL_SMELLS=$((TOTAL_SMELLS + CUSTOM_COUNT))
          
          echo $TOTAL_SMELLS > test_smells.txt
          echo "Total C++ test smells: $TOTAL_SMELLS"

      # =======================
      # Java Configuration
      # =======================
      - name: Setup JDK
        if: ${{ github.event.inputs.language == 'java' }}
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Run Java tests with comprehensive metrics
        if: ${{ github.event.inputs.language == 'java' }}
        run: |
          set +e
          
          # Detect build tool
          BUILD_TOOL=""
          if [ -f "pom.xml" ]; then
            BUILD_TOOL="maven"
          elif [ -f "build.gradle" ] || [ -f "build.gradle.kts" ]; then
            BUILD_TOOL="gradle"
          fi
          
          echo "Build tool: $BUILD_TOOL"
          
          if [ "$BUILD_TOOL" = "maven" ]; then
            # Ensure JaCoCo and PIT plugins are configured
            if ! grep -q "jacoco-maven-plugin" pom.xml; then
              echo "Adding JaCoCo plugin to pom.xml"
              # This would need proper XML manipulation in production
            fi
            
            # Clean compile
            mvn clean compile 2>&1 | tee compile_output.txt
            if [ $? -ne 0 ]; then
              echo "BUILD_FAILED" > build_fail.txt
              exit 0
            fi
            
            # Run tests with JaCoCo
            mvn test jacoco:report 2>&1 | tee test_output.txt
            TEST_EXIT=$?
            
            if [ $TEST_EXIT -ne 0 ]; then
              echo "TESTS_FAILED" > test_fail.txt
            fi
            
            # Generate reports
            mvn jacoco:report 2>&1 || true
            
            # Run mutation testing
            mvn org.pitest:pitest-maven:mutationCoverage \
              -DtargetClasses="*" \
              -DtargetTests="*Test" \
              -DoutputFormats=XML,HTML \
              -DtimestampedReports=false \
              2>&1 | tee pitest_output.txt || echo "MUTATION_FAILED" > mutation_fail.txt
              
          elif [ "$BUILD_TOOL" = "gradle" ]; then
            # Gradle commands
            ./gradlew clean build 2>&1 | tee build_output.txt
            if [ $? -ne 0 ]; then
              echo "BUILD_FAILED" > build_fail.txt
              exit 0
            fi
            
            ./gradlew test jacocoTestReport 2>&1 | tee test_output.txt
            TEST_EXIT=$?
            
            if [ $TEST_EXIT -ne 0 ]; then
              echo "TESTS_FAILED" > test_fail.txt
            fi
            
            # Run mutation testing with PIT
            ./gradlew pitest 2>&1 | tee pitest_output.txt || echo "MUTATION_FAILED" > mutation_fail.txt
          fi

      - name: Detect Java test smells
        if: ${{ github.event.inputs.language == 'java' }}
        run: |
          echo "=== Detecting Java Test Smells ==="
          curl -L https://github.com/TestSmells/TestSmellDetector/releases/download/v1.0/TestSmellDetector.jar -o TestSmellDetector.jar
          TEST_DIR=$(find . -type d -name "test" -o -name "tests" | head -1)
          if [ -n "$TEST_DIR" ]; then
            java -jar TestSmellDetector.jar -i $TEST_DIR -o java_smells.txt || true
          else
            echo "NO_TESTS_FOUND" > java_smells.txt
          fi

      ############################################################
      # KOTLIN
      ############################################################
      - name: Setup JDK for Kotlin
        if: ${{ github.event.inputs.language == 'kotlin' }}
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'

      - name: Run Kotlin tests with comprehensive metrics
        if: ${{ github.event.inputs.language == 'kotlin' }}
        run: |
          set +e
          ./gradlew clean build jacocoTestReport | tee kotlin_test_output.txt || echo "TESTS_FAILED" > test_fail.txt
          ./gradlew pitest | tee kotlin_pitest_output.txt || echo "MUTATION_FAILED" > mutation_fail.txt
          ./gradlew detekt || true
          cp build/reports/detekt/detekt.xml detekt_report.xml || true

      ############################################################
      # GO
      ############################################################
      - name: Setup Go
        if: ${{ github.event.inputs.language == 'go' }}
        uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Run Go tests with coverage and mutation
        if: ${{ github.event.inputs.language == 'go' }}
        run: |
          set +e
          go build ./... 2>&1 | tee compile_output.txt || echo "BUILD_FAILED" > build_fail.txt
          go test ./... -v -coverprofile=coverage.out 2>&1 | tee test_output.txt || echo "TESTS_FAILED" > test_fail.txt
          go install github.com/gtramontina/ooze@latest
          ooze run ./... > go_mutation.txt || echo "MUTATION_FAILED" > mutation_fail.txt
          go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest
          golangci-lint run ./... --out-format checkstyle > golangci-lint.xml || true

      ############################################################
      # UPLOAD REPORTS
      ############################################################
      - name: Collect reports
        run: |
          mkdir -p reports
          cp -r *.xml *.txt *.html *.out *.info *.json coverage* mutation* *output.txt reports/ 2>/dev/null || true

      - name: Upload consolidated reports
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ github.event.inputs.pr_number }}-metrics
          path: reports
          
      # =======================
      # Debug and Artifacts
      # =======================
      - name: Debug file structure
        if: always()
        run: |
          echo "=== Current directory structure ==="
          ls -la
          echo ""
          echo "=== Coverage files ==="
          find . -name "coverage*" -type f 2>/dev/null | head -20
          echo ""
          echo "=== Test output files ==="
          find . -name "*test*.txt" -o -name "*test*.xml" 2>/dev/null | head -20
          echo ""
          echo "=== Mutation files ==="
          find . -name "*mutation*" -o -name "*mutant*" -o -name "*pit-reports*" 2>/dev/null | head -20

      - name: Parse and summarize metrics
        if: always()
        run: |
          python3 <<'EOF'
          # (keep the full Python summarizer you pasted here)
          EOF

      - name: Upload consolidated metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ github.event.inputs.pr_number.sec }}-metrics
          path: |
            reports
            metrics.json
            metrics_summary.md
          retention-days: 30

      - name: Generate job summary
        if: always()
        run: |
          if [ -f "metrics_summary.md" ]; then
            cat metrics_summary.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No metrics summary available" >> $GITHUB_STEP_SUMMARY
          fi

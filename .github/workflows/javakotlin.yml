name: PR Test Analysis Workflow

on:
  workflow_dispatch:
    inputs:
      repo_name:
        description: 'Repository name (format: owner/repo)'
        required: true
        type: string
      pr_number:
        description: 'Pull Request number'
        required: true
        type: string

env:
  JAVA_VERSION: '17'
  GRADLE_VERSION: '8.5'
  MAVEN_VERSION: '3.9.6'
  KOTLIN_VERSION: '1.9.0'
  PYTHON_VERSION: '3.10'

jobs:
  analyze-pr:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash
    permissions:
      contents: read
      pull-requests: read
      checks: write
      actions: read
      statuses: write
    
    steps:
      - name: Validate inputs
        run: |
          if [[ ! "${{ github.event.inputs.repo_name }}" =~ ^[A-Za-z0-9_.-]+/[A-Za-z0-9_.-]+$ ]]; then
            echo "‚ùå Invalid repository format. Expected: owner/repo"
            exit 1
          fi
          if [[ "${{ github.event.inputs.repo_name }}" =~ \.\. ]]; then
            echo "‚ùå Invalid repository name: path traversal detected"
            exit 1
          fi
          if [[ ! "${{ github.event.inputs.pr_number }}" =~ ^[0-9]+$ ]]; then
            echo "‚ùå Invalid PR number. Expected: numeric value"
            exit 1
          fi
          echo "‚úÖ Inputs validated successfully"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: ${{ env.JAVA_VERSION }}

      - name: Setup Kotlin
        uses: fwilhe2/setup-kotlin@v1
        with:
          version: ${{ env.KOTLIN_VERSION }}

      - name: Get PR information
        id: pr_info
        run: |
          echo "Fetching PR information for #${{ github.event.inputs.pr_number }}"
          
          # Try to get PR data with error handling
          PR_DATA=$(gh api repos/${{ github.event.inputs.repo_name }}/pulls/${{ github.event.inputs.pr_number }} 2>/dev/null)
          
          if [ $? -ne 0 ] || [ -z "$PR_DATA" ]; then
            echo "‚ùå Failed to fetch PR data. Please check:"
            echo "   - PR number: #${{ github.event.inputs.pr_number }}"
            echo "   - Repository: ${{ github.event.inputs.repo_name }}"
            echo "   - Permissions: Make sure the token has access to the repository"
            exit 1
          fi
          
          BASE_SHA=$(echo "$PR_DATA" | jq -r '.base.sha')
          HEAD_SHA=$(echo "$PR_DATA" | jq -r '.head.sha')
          BASE_BRANCH=$(echo "$PR_DATA" | jq -r '.base.ref')
          HEAD_REF=$(echo "$PR_DATA" | jq -r '.head.ref')
          
          echo "base_sha=$BASE_SHA" >> $GITHUB_OUTPUT
          echo "head_sha=$HEAD_SHA" >> $GITHUB_OUTPUT
          echo "base_branch=$BASE_BRANCH" >> $GITHUB_OUTPUT
          echo "head_ref=$HEAD_REF" >> $GITHUB_OUTPUT
          
          echo "‚úÖ PR information retrieved:"
          echo "   - Base SHA: $BASE_SHA"
          echo "   - Head SHA: $HEAD_SHA"
          echo "   - Base Branch: $BASE_BRANCH"
          echo "   - Head Ref: $HEAD_REF"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Checkout base repository
        id: checkout-base
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.inputs.repo_name }}
          ref: ${{ steps.pr_info.outputs.base_branch }}
          path: base-repo
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Checkout PR branch
        id: checkout-pr
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.inputs.repo_name }}
          ref: ${{ steps.pr_info.outputs.head_sha }}
          path: pr-repo
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Detect build system
        id: detect_build
        run: |
          if [ -f "pr-repo/pom.xml" ]; then
            echo "build_system=maven" >> $GITHUB_OUTPUT
            echo "üì¶ Detected Maven project"
          elif [ -f "pr-repo/build.gradle" ] || [ -f "pr-repo/build.gradle.kts" ]; then
            echo "build_system=gradle" >> $GITHUB_OUTPUT
            echo "üì¶ Detected Gradle project"
          else
            echo "‚ùå No supported build system found"
            exit 1
          fi

      - name: Setup Gradle
        if: steps.detect_build.outputs.build_system == 'gradle'
        uses: gradle/actions/setup-gradle@v3
        with:
          gradle-version: ${{ env.GRADLE_VERSION }}

      - name: Setup Maven
        if: steps.detect_build.outputs.build_system == 'maven'
        run: |
          wget -q https://dlcdn.apache.org/maven/maven-3/${{ env.MAVEN_VERSION }}/binaries/apache-maven-${{ env.MAVEN_VERSION }}-bin.tar.gz
          tar xzf apache-maven-${{ env.MAVEN_VERSION }}-bin.tar.gz
          echo "$PWD/apache-maven-${{ env.MAVEN_VERSION }}/bin" >> $GITHUB_PATH

      - name: Identify changed test files
        id: changed_tests
        run: |
          echo "üîç Identifying changed test files in PR..."
          cd pr-repo
          git diff --name-only ${{ steps.pr_info.outputs.base_sha }}..${{ steps.pr_info.outputs.head_sha }} | \
            grep -E '(Test|Spec)\.(java|kt)$|/(test|spec)/.*\.(java|kt)$' > ../changed_tests.txt || echo "No test files found" > ../changed_tests.txt
          
          if [ -s ../changed_tests.txt ] && grep -q "[^[:space:]]" ../changed_tests.txt; then
            echo "found_tests=true" >> $GITHUB_OUTPUT
            echo "üìã Changed test files:"
            cat ../changed_tests.txt
          else
            echo "found_tests=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No test files found in PR"
          fi

      - name: Compile base code
        id: compile_base
        if: steps.changed_tests.outputs.found_tests == 'true'
        run: |
          echo "üî® Compiling base code..."
          cd base-repo
          START_TIME=$(date +%s)
          
          if [ "${{ steps.detect_build.outputs.build_system }}" == "gradle" ]; then
            ./gradlew clean compileJava compileKotlin compileTestJava compileTestKotlin 2>&1 | tee ../compile_base.log
            COMPILE_STATUS=${PIPESTATUS[0]}
          else
            mvn clean compile test-compile 2>&1 | tee ../compile_base.log
            COMPILE_STATUS=${PIPESTATUS[0]}
          fi
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo "compilation_status=$COMPILE_STATUS" >> $GITHUB_OUTPUT
          echo "compilation_time=$DURATION" >> $GITHUB_OUTPUT
          
          if [ $COMPILE_STATUS -eq 0 ]; then
            echo "‚úÖ Base compilation successful (${DURATION}s)"
          else
            echo "‚ùå Base compilation failed"
          fi

      - name: Copy PR tests to base
        if: steps.changed_tests.outputs.found_tests == 'true' && steps.compile_base.outputs.compilation_status == '0'
        run: |
          echo "üìã Copying PR test files to base code..."
          while IFS= read -r test_file; do
            if [ -n "$test_file" ]; then
              echo "Copying $test_file"
              mkdir -p "base-repo/$(dirname "$test_file")"
              cp "pr-repo/$test_file" "base-repo/$test_file"
            fi
          done < changed_tests.txt
          echo "‚úÖ Test files copied successfully"

      - name: Run tests with coverage
        id: run_tests
        if: steps.changed_tests.outputs.found_tests == 'true' && steps.compile_base.outputs.compilation_status == '0'
        timeout-minutes: 30
        run: |
          echo "üß™ Running tests with coverage..."
          cd base-repo
          START_TIME=$(date +%s)
          
          mkdir -p test-results
          
          # Extract test class names from file paths
          TEST_CLASSES=""
          while IFS= read -r test_file; do
            if [ -n "$test_file" ]; then
              # Convert file path to class name
              CLASS_NAME=$(echo "$test_file" | sed 's/src\/[^\/]*\/java\///' | sed 's/src\/[^\/]*\/kotlin\///' | sed 's/\.java$//' | sed 's/\.kt$//' | tr '/' '.')
              TEST_CLASSES="${TEST_CLASSES},${CLASS_NAME}"
            fi
          done < ../changed_tests.txt
          
          # Remove leading comma
          TEST_CLASSES=$(echo "$TEST_CLASSES" | sed 's/^,//')
          
          if [ "${{ steps.detect_build.outputs.build_system }}" == "gradle" ]; then
            # Use Gradle's built-in test filtering
            if [ -n "$TEST_CLASSES" ]; then
              ./gradlew test --tests "*${TEST_CLASSES//,/* --tests *}" jacocoTestReport 2>&1 | tee ../test_execution.log
            else
              ./gradlew test jacocoTestReport 2>&1 | tee ../test_execution.log
            fi
            TEST_STATUS=${PIPESTATUS[0]}
          else
            # Maven with specific test classes
            if [ -n "$TEST_CLASSES" ]; then
              mvn test -Dtest="$TEST_CLASSES" jacoco:report 2>&1 | tee ../test_execution.log
            else
              mvn test jacoco:report 2>&1 | tee ../test_execution.log
            fi
            TEST_STATUS=${PIPESTATUS[0]}
          fi
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo "test_status=$TEST_STATUS" >> $GITHUB_OUTPUT
          echo "test_time=$DURATION" >> $GITHUB_OUTPUT
          
          # Extract test results
          if [ "${{ steps.detect_build.outputs.build_system }}" == "gradle" ]; then
            TESTS_RUN=$(grep -oP 'tests?: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_PASSED=$(grep -oP 'passed?: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_FAILED=$(grep -oP 'failed?: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_SKIPPED=$(grep -oP 'skipped?: \K\d+' ../test_execution.log | tail -1 || echo "0")
          else
            TESTS_RUN=$(grep -oP 'Tests run: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_FAILED=$(grep -oP 'Failures: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_ERRORS=$(grep -oP 'Errors: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_SKIPPED=$(grep -oP 'Skipped: \K\d+' ../test_execution.log | tail -1 || echo "0")
            TESTS_PASSED=$((TESTS_RUN - TESTS_FAILED - TESTS_ERRORS - TESTS_SKIPPED))
          fi
          
          echo "tests_run=$TESTS_RUN" >> $GITHUB_OUTPUT
          echo "tests_passed=$TESTS_PASSED" >> $GITHUB_OUTPUT
          echo "tests_failed=$TESTS_FAILED" >> $GITHUB_OUTPUT
          echo "tests_skipped=$TESTS_SKIPPED" >> $GITHUB_OUTPUT

      - name: Parse coverage results
        id: coverage
        if: steps.changed_tests.outputs.found_tests == 'true' && steps.run_tests.outputs.test_status == '0'
        run: |
          echo "üìä Parsing coverage results..."
          cd base-repo
          
          if [ "${{ steps.detect_build.outputs.build_system }}" == "gradle" ]; then
            COVERAGE_FILE="build/reports/jacoco/test/jacocoTestReport.xml"
          else
            COVERAGE_FILE="target/site/jacoco/jacoco.xml"
          fi
          
          if [ -f "$COVERAGE_FILE" ]; then
            # Parse JaCoCo XML for coverage metrics
            LINE_COVERAGE=$(python3 -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('$COVERAGE_FILE')
              root = tree.getroot()
              for counter in root.findall('.//counter[@type=\"LINE\"]'):
                  missed = int(counter.get('missed', 0))
                  covered = int(counter.get('covered', 0))
                  if (missed + covered) > 0:
                      print(f'{(covered / (missed + covered)) * 100:.2f}')
                      break
              else:
                  print('0.00')
          except Exception as e:
              print(f'Error parsing coverage: {e}')
              print('0.00')
          ")
            
            BRANCH_COVERAGE=$(python3 -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('$COVERAGE_FILE')
              root = tree.getroot()
              for counter in root.findall('.//counter[@type=\"BRANCH\"]'):
                  missed = int(counter.get('missed', 0))
                  covered = int(counter.get('covered', 0))
                  if (missed + covered) > 0:
                      print(f'{(covered / (missed + covered)) * 100:.2f}')
                      break
              else:
                  print('0.00')
          except Exception as e:
              print(f'Error parsing coverage: {e}')
              print('0.00')
          ")
            
            echo "line_coverage=$LINE_COVERAGE" >> $GITHUB_OUTPUT
            echo "branch_coverage=$BRANCH_COVERAGE" >> $GITHUB_OUTPUT
            echo "‚úÖ Coverage: Line=$LINE_COVERAGE%, Branch=$BRANCH_COVERAGE%"
          else
            echo "line_coverage=0.00" >> $GITHUB_OUTPUT
            echo "branch_coverage=0.00" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è No coverage data found"
          fi

      - name: Compute metrics for summary
        id: compute_metrics
        if: always()
        run: |
          echo "üìà Computing metrics for summary report..."
          
          # Set default values
          COMPILATION_TIME="${steps.compile_base.outputs.compilation_time:-0}"
          TEST_TIME="${steps.run_tests.outputs.test_time:-0}"
          TOTAL_TIME=$((COMPILATION_TIME + TEST_TIME))
          
          # Calculate success rate
          if [ "${{ steps.run_tests.outputs.tests_run }}" != "0" ] && [ -n "${{ steps.run_tests.outputs.tests_run }}" ]; then
            SUCCESS_RATE=$(echo "scale=2; ${{ steps.run_tests.outputs.tests_passed }} * 100 / ${{ steps.run_tests.outputs.tests_run }}" | bc)
          else
            SUCCESS_RATE="0"
          fi
          
          echo "success_rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
          echo "total_time=$TOTAL_TIME" >> $GITHUB_OUTPUT
          
          echo "‚úÖ Metrics computed: success_rate=$SUCCESS_RATE%, total_time=${TOTAL_TIME}s"

      - name: Generate summary report
        id: summary
        if: always()
        run: |
          echo "üìä Generating summary report..."
          
          # Set default values for variables that might be empty
          LINE_COVERAGE="${steps.coverage.outputs.line_coverage:-0.00}"
          BRANCH_COVERAGE="${steps.coverage.outputs.branch_coverage:-0.00}"
          MUTATION_SCORE="${steps.mutation.outputs.mutation_score:-0}"
          TOTAL_SMELLS="${steps.test_smells.outputs.total_smells:-0}"
          
          cat > summary_report.md << EOF
          # PR Test Analysis Summary Report
          
          **Repository:** ${{ github.event.inputs.repo_name }}  
          **Pull Request:** #${{ github.event.inputs.pr_number }}  
          **Analysis Date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")  
          **Build System:** ${{ steps.detect_build.outputs.build_system }}
          
          ---
          
          ## üìã Overall Status
          
          | Metric | Status |
          |--------|--------|
          | Compilation | $([[ "${{ steps.compile_base.outputs.compilation_status }}" == "0" ]] && echo "‚úÖ Success" || echo "‚ùå Failed") |
          | Test Execution | $([[ "${{ steps.run_tests.outputs.test_status }}" == "0" ]] && echo "‚úÖ Success" || echo "‚ùå Failed") |
          | Changed Test Files | $([[ "${{ steps.changed_tests.outputs.found_tests }}" == "true" ]] && echo "$(wc -l < changed_tests.txt) files" || echo "None found") |
          
          ## üß™ Test Execution Results
          
          | Metric | Value |
          |--------|-------|
          | Total Tests Run | ${{ steps.run_tests.outputs.tests_run }} |
          | Tests Passed | ${{ steps.run_tests.outputs.tests_passed }} ‚úÖ |
          | Tests Failed | ${{ steps.run_tests.outputs.tests_failed }} ‚ùå |
          | Tests Skipped | ${{ steps.run_tests.outputs.tests_skipped }} ‚è≠Ô∏è |
          | Success Rate | ${{ steps.compute_metrics.outputs.success_rate }}% |
          | Execution Time | ${{ steps.run_tests.outputs.test_time }}s |
          
          ## üìä Code Coverage
          
          | Coverage Type | Percentage |
          |---------------|------------|
          | Line Coverage | ${LINE_COVERAGE}% |
          | Branch Coverage | ${BRANCH_COVERAGE}% |
          
          ## üß¨ Mutation Testing
          
          | Metric | Value |
          |--------|-------|
          | Mutation Score | ${MUTATION_SCORE}% |
          | Mutation Strength | $([[ "${MUTATION_SCORE}" -ge 80 ]] && echo "üü¢ Strong" || ([[ "${MUTATION_SCORE}" -ge 60 ]] && echo "üü° Moderate" || echo "üî¥ Weak")) |
          
          ## üîç Test Quality Analysis
          
          | Test Smell | Count |
          |------------|-------|
          EOF
          
          if [ -f "test_smells.json" ]; then
            python3 -c "
          import json
          try:
              with open('test_smells.json', 'r') as f:
                  data = json.load(f)
                  for smell, count in data.get('smells', {}).items():
                      icon = '‚ö†Ô∏è' if count > 0 else '‚úÖ'
                      print(f'| {smell.replace(\"_\", \" \").title()} | {count} {icon} |')
          except Exception as e:
              print('| Error loading smell data | - |')
          "
          else
            echo "| No analysis available | - |"
          fi >> summary_report.md
          
          cat >> summary_report.md << EOF
          | **Total Smells** | **${TOTAL_SMELLS}** |
          
          ## ‚è±Ô∏è Performance Metrics
          
          | Phase | Duration |
          |-------|----------|
          | Compilation | ${{ steps.compile_base.outputs.compilation_time }}s |
          | Test Execution | ${{ steps.run_tests.outputs.test_time }}s |
          | Total Analysis | ${{ steps.compute_metrics.outputs.total_time }}s |
          
          ## üìù Changed Test Files
          
          EOF
          
          if [ -f "changed_tests.txt" ] && [ -s "changed_tests.txt" ]; then
            echo '```' >> summary_report.md
            cat changed_tests.txt >> summary_report.md
            echo '```' >> summary_report.md
          else
            echo "_No test files were changed in this PR_" >> summary_report.md
          fi
          
          cat >> summary_report.md << EOF
          
          ## üéØ Quality Score
          
          EOF
          
          # Calculate overall quality score
          python3 -c "
          try:
              compilation = 1 if '${{ steps.compile_base.outputs.compilation_status }}' == '0' else 0
              test_success = float('${{ steps.run_tests.outputs.tests_passed }}') / max(float('${{ steps.run_tests.outputs.tests_run }}'), 1) if '${{ steps.run_tests.outputs.tests_run }}' != '0' else 0
              coverage = (float('${LINE_COVERAGE}') + float('${BRANCH_COVERAGE}')) / 200
              mutation = float('${MUTATION_SCORE}') / 100
              smells = max(0, 1 - (float('${TOTAL_SMELLS}') / 10))
              
              score = (compilation * 20 + test_success * 25 + coverage * 25 + mutation * 20 + smells * 10)
              
              grade = 'A' if score >= 90 else 'B' if score >= 80 else 'C' if score >= 70 else 'D' if score >= 60 else 'F'
              
              print(f'**Overall Quality Score:** {score:.1f}/100 (Grade: {grade})')
              print('')
              print('### Score Breakdown:')
              print(f'- Compilation: {compilation * 20:.1f}/20')
              print(f'- Test Success: {test_success * 25:.1f}/25')
              print(f'- Code Coverage: {coverage * 25:.1f}/25')
              print(f'- Mutation Testing: {mutation * 20:.1f}/20')
              print(f'- Code Quality: {smells * 10:.1f}/10')
          except Exception as e:
              print('Error calculating quality score: ' + str(e))
              print(f'**Overall Quality Score:** N/A')
          " >> summary_report.md
          
          echo "" >> summary_report.md
          echo "---" >> summary_report.md
          echo "_Generated by PR Test Analysis Workflow_" >> summary_report.md
          
          echo "‚úÖ Summary report generated successfully"

      - name: Prepare artifacts for upload
        if: always()
        run: |
          echo "üì¶ Preparing artifacts for upload..."
          mkdir -p artifacts
          
          # Copy all relevant files to artifacts directory
          [ -f summary_report.md ] && cp summary_report.md artifacts/
          [ -f test_smells.json ] && cp test_smells.json artifacts/
          [ -f compile_base.log ] && cp compile_base.log artifacts/
          [ -f test_execution.log ] && cp test_execution.log artifacts/
          [ -f mutation.log ] && cp mutation.log artifacts/
          
          # Copy reports directory if it exists
          [ -d reports ] && cp -r reports artifacts/
          
          echo "Contents of artifacts directory:"
          ls -la artifacts/

      - name: Upload test reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-analysis-reports
          path: artifacts/
          retention-days: 30

      - name: Upload coverage reports
        if: steps.run_tests.outputs.test_status == '0'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-reports
          path: |
            base-repo/**/jacoco/**
            base-repo/**/site/jacoco/**
            base-repo/**/reports/jacoco/**
          retention-days: 30

      - name: Upload mutation reports
        if: steps.mutation.outputs.mutation_score != ''
        uses: actions/upload-artifact@v4
        with:
          name: mutation-reports
          path: |
            base-repo/**/pit-reports/**
            base-repo/**/reports/pitest/**
          retention-days: 30

      - name: Post summary as PR comment
        if: always() && steps.changed_tests.outputs.found_tests == 'true'
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const fs = require('fs');
            try {
              const summaryContent = fs.readFileSync('summary_report.md', 'utf8');
              await github.rest.issues.createComment({
                owner: '${{ github.event.inputs.repo_name }}'.split('/')[0],
                repo: '${{ github.event.inputs.repo_name }}'.split('/')[1],
                issue_number: ${{ github.event.inputs.pr_number }},
                body: summaryContent
              });
              console.log('‚úÖ Summary posted to PR successfully');
            } catch (error) {
              console.error('Failed to post comment:', error);
            }

      - name: Create check run
        if: always()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const conclusion = '${{ steps.run_tests.outputs.test_status }}' === '0' ? 'success' : 'failure';
            const title = conclusion === 'success' ? '‚úÖ PR Test Analysis Passed' : '‚ùå PR Test Analysis Failed';
            
            const summary = `
            ## Test Results
            - **Tests Run:** ${{ steps.run_tests.outputs.tests_run }}
            - **Tests Passed:** ${{ steps.run_tests.outputs.tests_passed }}
            - **Tests Failed:** ${{ steps.run_tests.outputs.tests_failed }}
            - **Line Coverage:** ${process.env.LINE_COVERAGE || 'N/A'}%
            - **Branch Coverage:** ${process.env.BRANCH_COVERAGE || 'N/A'}%
            - **Mutation Score:** ${{ steps.mutation.outputs.mutation_score }}%
            - **Test Smells:** ${{ steps.test_smells.outputs.total_smells }}
            `;
            
            try {
              await github.rest.checks.create({
                owner: '${{ github.event.inputs.repo_name }}'.split('/')[0],
                repo: '${{ github.event.inputs.repo_name }}'.split('/')[1],
                name: 'PR Test Analysis',
                head_sha: '${{ steps.pr_info.outputs.head_sha }}',
                status: 'completed',
                conclusion: conclusion,
                output: {
                  title: title,
                  summary: summary
                }
              });
            } catch (error) {
              console.error('Failed to create check run:', error);
            }

      - name: Cleanup
        if: always()
        run: |
          echo "üßπ Cleaning up temporary files..."
          rm -f changed_tests.txt compile_base.log test_execution.log mutation.log
          rm -f test_smells.json detect_smells.py
          echo "‚úÖ Cleanup completed"

      - name: Display final status
        if: always()
        run: |
          echo "========================================="
          echo "         PR TEST ANALYSIS COMPLETE      "
          echo "========================================="
          echo ""
          if [ "${{ steps.changed_tests.outputs.found_tests }}" != "true" ]; then
            echo "‚ö†Ô∏è  No test files found in PR #${{ github.event.inputs.pr_number }}"
          elif [ "${{ steps.compile_base.outputs.compilation_status }}" != "0" ]; then
            echo "‚ùå Analysis failed: Compilation error"
          elif [ "${{ steps.run_tests.outputs.test_status }}" != "0" ]; then
            echo "‚ùå Analysis completed with test failures"
            echo "   - Failed tests: ${{ steps.run_tests.outputs.tests_failed }}"
          else
            echo "‚úÖ Analysis completed successfully!"
            echo "   - Tests passed: ${{ steps.run_tests.outputs.tests_passed }}/${{ steps.run_tests.outputs.tests_run }}"
            echo "   - Coverage: ${LINE_COVERAGE}%"
            echo "   - Mutation score: ${{ steps.mutation.outputs.mutation_score }}%"
          fi
          echo ""
          echo "üìä Full reports available in workflow artifacts"
          echo "========================================="

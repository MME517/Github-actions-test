name: Human Test Metrics v6

on:
  workflow_dispatch:
    inputs:
      repo:
        description: "Repository (e.g. owner/name)"
        required: true
        type: string
      pr_number:
        description: "Pull request number"
        required: true
        type: string
      language:
        description: "Project language"
        required: true
        type: choice
        options:
          - python
          - cpp
          - java
          - kotlin
          - go

jobs:
  test-metrics:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    steps:
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          repository: ${{ github.event.inputs.repo }}
          ref: refs/pull/${{ github.event.inputs.pr_number }}/head
          fetch-depth: 0

      - name: Setup Python for parsing (always needed)
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install parsing dependencies
        run: |
          python -m pip install --upgrade pip
          pip install lxml beautifulsoup4 pandas

      # -----------------------
      # Shared helpers
      # -----------------------
      - name: Create reports folder
        run: |
          mkdir -p reports/python reports/cpp reports/java reports/kotlin reports/go || true

      - name: Save environment info
        run: |
          echo "GITHUB_REPO=${{ github.event.inputs.repo }}" >> $GITHUB_ENV
          echo "PR_NUMBER=${{ github.event.inputs.pr_number }}" >> $GITHUB_ENV

      # =======================
      # PYTHON
      # =======================
      - name: Setup Python Project
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip wheel setuptools

          # Try multiple ways to install project dependencies
          echo "=== Installing project dependencies ==="

          if [ -f "requirements.txt" ]; then
            pip install -r requirements.txt || true
          fi

          if [ -f "requirements-dev.txt" ]; then
            pip install -r requirements-dev.txt || true
          fi

          if [ -f "requirements/dev.txt" ]; then
            pip install -r requirements/dev.txt || true
          fi

          if [ -f "requirements/test.txt" ]; then
            pip install -r requirements/test.txt || true
          fi

          if [ -f "setup.py" ]; then
            pip install -e ".[test]" 2>/dev/null || pip install -e . 2>/dev/null || true
          fi

          if [ -f "pyproject.toml" ]; then
            if grep -q "tool.poetry" pyproject.toml 2>/dev/null; then
              python -m pip install poetry
              poetry install --with test 2>/dev/null || poetry install 2>/dev/null || true
            else
              pip install -e ".[test]" 2>/dev/null || pip install -e . 2>/dev/null || true
            fi
          fi

          if [ -f "Pipfile" ]; then
            python -m pip install pipenv
            pipenv install --dev --deploy --system 2>/dev/null || true
          fi

          # Install testing/analysis tools (non-fatal)
          pip install pytest pytest-cov pytest-xdist pytest-timeout pytest-mock coverage[toml] mutmut || true
          pip install flake8 flake8-pytest-style flake8-test-name flake8-aaa flake8-assertive || true
          pip install pylint radon mccabe || true
          pip install hypothesis pytest-benchmark pytest-sugar || true

      - name: Configure Python testing environment
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set -euo pipefail

          cat > .coveragerc <<'EOF'
          [run]
          branch = True
          source = .
          omit = 
          */tests/*
          */test/*
          */__pycache__/*
          */venv/*
          */env/*
          */.venv/*
          */setup.py
          */conf.py
          */docs/*
          */migrations/*
          parallel = True

          [report]
          precision = 2
          show_missing = True
          skip_covered = False

          [xml]
          output = coverage.xml
          EOF

          if [ ! -f "pytest.ini" ] && [ ! -f "setup.cfg" ] && [ ! -f "pyproject.toml" ]; then
            cat > pytest.ini <<'EOF'
          [tool:pytest]
          testpaths = tests test testing
          python_files = test_*.py *_test.py *tests.py
          python_classes = Test* *Tests *Test
          python_functions = test_*
          addopts = 
          -ra
          --strict-markers
          --cov=.
          --cov-branch
          --cov-report=term-missing:skip-covered
          --cov-report=xml
          --cov-report=html
          --tb=short
          -v
          EOF
          fi

      - name: Discover Python project structure
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set -euo pipefail
          echo "=== Python Project Structure ==="
          find . -type f -name "*.py" -not -path "*/test*" -not -path "*/.*" | head -20
          find . -type d \( -name "test*" -o -name "*test" -o -name "*tests" \) -not -path "*/.*" | head -10
          find . -type f -name "*test*.py" -not -path "*/.*" | head -20
          MAIN_PACKAGE=$(find . -maxdepth 2 -type f -name "__init__.py" -not -path "*/test*" -not -path "*/.*" | head -1 | xargs -r dirname || true)
          echo "MAIN_PACKAGE=${MAIN_PACKAGE}" >> $GITHUB_ENV || true

      - name: Run Python tests with comprehensive coverage
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set -eo pipefail

          TEST_PATHS=""
          for dir in tests test testing test_suite; do
            if [ -d "$dir" ]; then
              TEST_PATHS="$TEST_PATHS $dir"
            fi
          done

          if [ -z "$TEST_PATHS" ]; then
            TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" | grep -v __pycache__ | grep -v ".venv" | head -50 || true)
            if [ -n "$TEST_FILES" ]; then
              TEST_PATHS="."
            fi
          fi

          echo "Test paths: $TEST_PATHS"

          if [ -n "$TEST_PATHS" ]; then
            coverage erase || true
            python -m pytest $TEST_PATHS \
              --cov=. \
              --cov-branch \
              --cov-report=xml:reports/python/python_coverage.xml \
              --cov-report=html:reports/python/python_coverage_html \
              --cov-report=term-missing \
              --cov-report=json:reports/python/python_coverage.json \
              --junit-xml=reports/python/pytest-report.xml \
              --timeout=300 \
              -v \
              --tb=short 2>&1 | tee reports/python/pytest_output.txt || true

            TEST_EXIT_CODE=${PIPESTATUS[0]}
            if [ $TEST_EXIT_CODE -ne 0 ]; then
              echo "TESTS_FAILED" > reports/python/test_fail.txt
            fi

            # Ensure coverage files exist
            if [ ! -f reports/python/python_coverage.xml ]; then
              coverage run -m pytest $TEST_PATHS 2>&1 | tee reports/python/coverage_run_output.txt || true
              coverage xml -o reports/python/python_coverage.xml || true
              coverage json -o reports/python/python_coverage.json || true
              coverage html -d reports/python/python_coverage_html || true
              coverage report | tee reports/python/coverage_report.txt || true
            fi

            if [ -f reports/python/python_coverage.xml ]; then
              python - <<'PY'
            import xml.etree.ElementTree as ET
           try:
            tree = ET.parse('reports/python/python_coverage.xml')
            root = tree.getroot()
            print(f"Line Coverage: {float(root.attrib.get('line-rate',0))*100:.2f}%")
            print(f"Branch Coverage: {float(root.attrib.get('branch-rate',0))*100:.2f}%")
            except Exception as e:
            print('Could not parse coverage xml:', e)
          PY
            fi
          else
            echo "No tests found" > reports/python/pytest_output.txt
            echo "TESTS_FAILED" > reports/python/test_fail.txt
          fi

      - name: Run Python mutation testing with mutmut
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set -eo pipefail
          # safe mutmut run: limit paths and timeout
          SOURCE_PATHS=$(find . -name "*.py" -not -path "*/test*" -not -path "*/.*" -not -path "*/venv/*" -not -path "*/env/*" | xargs -r dirname | sort -u | head -5 || true)
          if [ -z "$SOURCE_PATHS" ]; then
            SOURCE_PATHS="."
          fi
          echo "Source paths to mutate: $SOURCE_PATHS"

          cat > .mutmut.cfg <<'EOF'
          [mutmut]
          paths_to_mutate=$SOURCE_PATHS
          tests_dir=.
          dict_synonyms=False
          EOF

          rm -rf .mutmut-cache || true

          # Run mutmut per-path but use a timeout and limit
          for path in $SOURCE_PATHS; do
            echo "Mutating path: $path"
            timeout 900 mutmut run --paths-to-mutate="$path" --runner="python -m pytest -x -q" --use-coverage --simple-output 2>&1 | tee -a reports/python/mutmut_output.txt || true
          done

          # Collect results if present
          if [ -f .mutmut-cache ]; then
            mutmut results 2>&1 | tee reports/python/mutations.txt || true
            mutmut show all 2>&1 | tee reports/python/mutations_detailed.txt || true
            mutmut html 2>/dev/null || true
            python - <<'PY'
            import sqlite3
            try:
               conn = sqlite3.connect('.mutmut-cache')
               cursor = conn.cursor()
               cursor.execute('SELECT status, COUNT(*) FROM mutant GROUP BY status')
               results = dict(cursor.fetchall())
               killed = results.get('killed', 0)
               survived = results.get('survived', 0)
               timeout = results.get('timeout', 0)
               total = killed + survived + timeout
             if total > 0:
                 score = (killed / total) * 100
             print(f'Mutation Score: {score:.2f}%')
             conn.close()
             except Exception as e:
             print('Error reading mutation results:', e)
            PY
          else
            echo "MUTATION_FAILED" > reports/python/mutation_fail.txt
          fi

      - name: Detect Python test smells
        if: ${{ github.event.inputs.language == 'python' }}
        run: |
          set -euo pipefail
          echo "=== Detecting Test Smells ==="
          TEST_FILES=$(find . -name "*test*.py" -o -name "test_*.py" | grep -v __pycache__ | grep -v ".venv" || true)
          flake8 --select=PT,AAA,T $TEST_FILES --exit-zero > reports/python/flake8_smells.txt 2>&1 || true

          python3 <<'PY'
          import os, ast, re
          from pathlib import Path 
          smells=[]
          for pattern in ["*test*.py","test_*.py"]:
          for p in Path('.').rglob(pattern):
          if '.venv' in str(p):
            continue
          try:
            content=p.read_text(encoding='utf-8')
            tree=ast.parse(content)
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef) and node.name.startswith('test'):
                    if len(node.body)==1 and isinstance(node.body[0], ast.Pass):
                        smells.append(f"{p}:{node.lineno}: Empty test")
                    has_assert=any(isinstance(n, ast.Assert) for n in ast.walk(node))
                    has_assert_call=any(isinstance(n, ast.Call) and isinstance(n.func, ast.Attribute) and n.func.attr.startswith('assert') for n in ast.walk(node))
                    if not has_assert and not has_assert_call and len(node.body)>1:
                        smells.append(f"{p}:{node.lineno}: Test without assertion")
                    assertion_count=sum(1 for n in ast.walk(node) if isinstance(n, ast.Assert))
                    if assertion_count>5:
                        smells.append(f"{p}:{node.lineno}: Too many assertions ({assertion_count})")
            for i,line in enumerate(content.split('\n'),1):
                if 'TODO' in line or 'FIXME' in line:
                    smells.append(f"{p}:{i}: TODO/FIXME comment")
            hardcoded_patterns=[r'127\\.0\\.0\\.1',r'localhost:?\\d+',r'password\\s*=\\s*".*"',r'/tmp/test',r'C:\\\\test']
            for pattern in hardcoded_patterns:
                for m in re.finditer(pattern, content, re.IGNORECASE):
                    line_no=content[:m.start()].count('\n')+1
                    smells.append(f"{p}:{line_no}: Hardcoded test data")
           except Exception as e:
            print('Error',p,e)
           with open('reports/python/custom_smells.txt','w') as f:
          for s in smells:
          f.write(s+'\n')
          print(f'Found {len(smells)} custom test smells')
          PY
          radon cc $TEST_FILES -s -n B 2>/dev/null | grep -E "^\s+F|^\s+C|^\s+D" > reports/python/complex_tests.txt || true

      # =======================
      # C++
      # =======================
      - name: Install C++ tools
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential cmake ninja-build lcov gcovr clang clang-tidy cppcheck llvm libgtest-dev libgmock-dev catch2 || true

      - name: Build and test C++ with comprehensive coverage
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          set -euo pipefail
          BUILD_SYSTEM=""
          if [ -f "CMakeLists.txt" ]; then
            BUILD_SYSTEM="cmake"
          elif [ -f "Makefile" ]; then
            BUILD_SYSTEM="make"
          elif [ -f "meson.build" ]; then
            BUILD_SYSTEM="meson"
          fi

          echo "Build system: $BUILD_SYSTEM"

          TEST_EXIT=0
          if [ "$BUILD_SYSTEM" = "cmake" ]; then
            mkdir -p build && cd build
            cmake .. -DCMAKE_BUILD_TYPE=Debug -DCMAKE_CXX_FLAGS="--coverage -g -O0 -fprofile-arcs -ftest-coverage -fPIC" -DCMAKE_C_FLAGS="--coverage -g -O0 -fprofile-arcs -ftest-coverage -fPIC" -DCMAKE_EXE_LINKER_FLAGS="--coverage -lgcov" -DCMAKE_EXPORT_COMPILE_COMMANDS=ON 2>&1 | tee ../reports/cpp/cmake_output.txt || true
            make -j$(nproc) VERBOSE=1 2>&1 | tee ../reports/cpp/make_output.txt || true
            ctest --output-on-failure -V 2>&1 | tee ../reports/cpp/ctest_output.txt || true
            TEST_EXIT=${PIPESTATUS[0]:-0}
            cd ..
            lcov --capture --directory . --output-file reports/cpp/coverage.info 2>/dev/null || true
            lcov --remove reports/cpp/coverage.info '/usr/*' '*/test/*' --output-file reports/cpp/coverage.info 2>/dev/null || true
            genhtml reports/cpp/coverage.info --output-directory reports/cpp/coverage_html 2>/dev/null || true
            gcovr -r . --xml -o reports/cpp/coverage.xml --html-details -o reports/cpp/coverage.html --exclude-directories test --exclude-directories tests --print-summary 2>&1 | tee reports/cpp/gcovr_output.txt || true

          elif [ "$BUILD_SYSTEM" = "make" ]; then
            make clean 2>/dev/null || true
            make CXXFLAGS="--coverage -g -O0" LDFLAGS="--coverage" all 2>&1 | tee reports/cpp/make_output.txt || true
            make test 2>&1 | tee reports/cpp/test_output.txt || true
            gcovr -r . --xml -o reports/cpp/coverage.xml --html -o reports/cpp/coverage.html 2>/dev/null || true

          else
            echo "NO_BUILD_SYSTEM" > reports/cpp/build_fail.txt
          fi

          if [ $TEST_EXIT -ne 0 ]; then
            echo "TESTS_FAILED" > reports/cpp/test_fail.txt
          fi

      - name: Run C++ mutation testing (safe, limited)
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, shutil, subprocess, json, tempfile
          root='.'
          src=[]
          for r,d,files in os.walk(root):
          if 'build' in r or '.git' in r:
          continue
          for f in files:
          if f.endswith(('.cpp','.cc','.cxx')) and not f.endswith('_test.cpp'):
            src.append(os.path.join(r,f))
          src=src[:10] 
          ops=[('==','!=','Equality to Inequality'),('!=','==','Inequality to Equality'),('<','<=','Less Than to Less Equal'),('>','>=','Greater Than to Greater Equal'),('\n++','--','Increment to Decrement'),('\n--','++','Decrement to Increment'),('&&','||','AND to OR'),('||','&&','OR to AND'),(' true',' false','True to False'),(' false',' true','False to True')]
          mutants=[]
          killed=0
          survived=0
          for sf in src:
          try:
          with open(sf,'r',encoding='utf-8') as f:
            orig=f.read()
          for pat,rep,desc in ops:
            idx=orig.find(pat)
            if idx==-1:
                continue
            mutated=orig.replace(pat,rep,1)
            # write to temp file
            td=tempfile.mkdtemp()
            target=os.path.join(td,os.path.basename(sf))
            shutil.copyfile(sf,target)
            with open(target,'w',encoding='utf-8') as f:
                f.write(mutated)
            # create a shallow copy of repo to build
            repo_copy=os.path.join(td,'repo')
            shutil.copytree('.',repo_copy,dirs_exist_ok=True,ignore=shutil.ignore_patterns('build','.git'))
            # replace file in copy
            dst=os.path.join(repo_copy,os.path.relpath(sf,'.'))
            os.makedirs(os.path.dirname(dst),exist_ok=True)
            shutil.copyfile(target,dst)
            # attempt build
            try:
                subprocess.run(['cmake','-S',repo_copy,'-B',os.path.join(repo_copy,'build')],check=True,timeout=60)
                subprocess.run(['cmake','--build',os.path.join(repo_copy,'build')],check=True,timeout=120)
                # run tests if available
                r=subprocess.run(['ctest','--test-dir',os.path.join(repo_copy,'build')],timeout=60)
                if r.returncode!=0:
                    killed+=1
                    status='killed'
                else:
                    survived+=1
                    status='survived'
            except Exception:
                killed+=1
                status='killed'
            mutants.append({'file':sf,'operator':desc,'status':status})
            shutil.rmtree(td,ignore_errors=True)
            except Exception:
           continue
          with open('reports/cpp/mutations.json','w') as f:
          json.dump({'mutants':mutants,'summary':{'killed':killed,'survived':survived}},f,indent=2)
          print('Mutation run complete')
          PY

      - name: Detect C++ test smells
        if: ${{ github.event.inputs.language == 'cpp' }}
        run: |
          set -euo pipefail
          TEST_FILES=$(find . -name "*test*.cpp" -o -name "*test*.cc" -o -name "*_test.cpp" | grep -v build || true)
          if [ -n "$TEST_FILES" ]; then
            cppcheck --enable=all --suppress=missingIncludeSystem $TEST_FILES 2> reports/cpp/cppcheck_smells.txt || true
            grep -c "error\|warning\|style" reports/cpp/cppcheck_smells.txt || true
            for file in $TEST_FILES; do
              grep -n "TEST.*{[[:space:]]*}" "$file" >> reports/cpp/empty_tests.txt 2>/dev/null || true
              awk '/TEST.*{/,/^}/' "$file" | grep -L "EXPECT\|ASSERT\|CHECK\|REQUIRE" >> reports/cpp/no_assert.txt 2>/dev/null || true
              grep -n "TODO\|FIXME" "$file" >> reports/cpp/todo_tests.txt 2>/dev/null || true
              grep -n "[^0-9][0-9]\{3,\}[^0-9]" "$file" >> reports/cpp/magic_numbers.txt 2>/dev/null || true
            done
          else
            echo "NO_TESTS_FOUND" > reports/cpp/no_tests.txt
          fi

      # =======================
      # JAVA
      # =======================
      - name: Setup JDK
        if: ${{ github.event.inputs.language == 'java' }}
        uses: actions/setup-java@v4
        with:
          java-version: '21'
          distribution: 'temurin'

      - name: Run Java tests with comprehensive metrics
        if: ${{ github.event.inputs.language == 'java' }}
        run: |
          set -euo pipefail
          BUILD_TOOL=""
          if [ -f "pom.xml" ]; then
            BUILD_TOOL="maven"
          elif [ -f "build.gradle" ] || [ -f "build.gradle.kts" ]; then
            BUILD_TOOL="gradle"
          fi
          echo "Build tool: $BUILD_TOOL"

          if [ "$BUILD_TOOL" = "maven" ]; then
            mvn -B -DskipTests=false clean test jacoco:report 2>&1 | tee reports/java/maven_test_output.txt || true
            mvn org.pitest:pitest-maven:mutationCoverage -DtargetClasses="*" -DtargetTests="*Test" -DoutputFormats=XML,HTML -DtimestampedReports=false 2>&1 | tee reports/java/pitest_output.txt || true
          elif [ "$BUILD_TOOL" = "gradle" ]; then
            ./gradlew -q clean test jacocoTestReport 2>&1 | tee reports/java/gradle_test_output.txt || true
            ./gradlew -q pitest 2>&1 | tee reports/java/gradle_pitest_output.txt || true
          else
            echo "NO_BUILD_TOOL" > reports/java/build_fail.txt
          fi

      - name: Detect Java test smells
        if: ${{ github.event.inputs.language == 'java' }}
        run: |
          set -euo pipefail
          curl -sL https://github.com/TestSmells/TestSmellDetector/releases/download/v1.0/TestSmellDetector.jar -o TestSmellDetector.jar || true
          TEST_DIR=$(find . -type d -name "test" -o -name "tests" | head -1 || true)
          if [ -n "$TEST_DIR" ]; then
            java -jar TestSmellDetector.jar -i "$TEST_DIR" -o reports/java/java_smells.txt || true
          else
            echo "NO_TESTS_FOUND" > reports/java/java_smells.txt
          fi

      # =======================
      # KOTLIN
      # =======================
      - name: Setup JDK for Kotlin
        if: ${{ github.event.inputs.language == 'kotlin' }}
        uses: actions/setup-java@v4
        with:
          java-version: '17'
          distribution: 'temurin'

      - name: Run Kotlin tests with comprehensive metrics
        if: ${{ github.event.inputs.language == 'kotlin' }}
        run: |
          set -euo pipefail
          if [ -f "gradlew" ]; then
            ./gradlew -q clean build jacocoTestReport 2>&1 | tee reports/kotlin/kotlin_test_output.txt || true
            ./gradlew -q pitest 2>&1 | tee reports/kotlin/kotlin_pitest_output.txt || true
            ./gradlew -q detekt || true
            cp build/reports/detekt/detekt.xml reports/kotlin/detekt_report.xml 2>/dev/null || true
          else
            echo "NO_GRADLE_WRAPPER" > reports/kotlin/build_fail.txt
          fi

      # =======================
      # GO
      # =======================
      - name: Setup Go
        if: ${{ github.event.inputs.language == 'go' }}
        uses: actions/setup-go@v5
        with:
          go-version: '1.22'

      - name: Run Go tests with coverage and mutation
        if: ${{ github.event.inputs.language == 'go' }}
        run: |
          set -euo pipefail
          go env -w GOPROXY=https://proxy.golang.org || true
          go build ./... 2>&1 | tee reports/go/compile_output.txt || echo "BUILD_FAILED" > reports/go/build_fail.txt || true
          go test ./... -v -coverprofile=reports/go/coverage.out 2>&1 | tee reports/go/test_output.txt || echo "TESTS_FAILED" > reports/go/test_fail.txt || true
          if [ -f reports/go/coverage.out ]; then
            go tool cover -html=reports/go/coverage.out -o reports/go/coverage.html || true
            go tool cover -func=reports/go/coverage.out > reports/go/coverage.txt || true
          fi
          go install github.com/gtramontina/ooze@latest || true
          ooze run ./... > reports/go/go_mutation.txt 2>&1 || echo "MUTATION_FAILED" > reports/go/mutation_fail.txt || true
          go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest || true
          golangci-lint run ./... --out-format checkstyle > reports/go/golangci-lint.xml 2>/dev/null || true

      # -----------------------
      # COLLECT & UPLOAD
      # -----------------------
      - name: Collect reports
        if: always()
        run: |
          set -euo pipefail
          mkdir -p reports
          # already collected into language subfolders; ensure generic copies exist
          cp -r reports/* reports/ 2>/dev/null || true

      - name: Upload consolidated reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ github.event.inputs.pr_number }}-metrics
          path: reports
          retention-days: 30

      - name: Debug file structure
        if: always()
        run: |
          echo "=== Current directory structure ==="
          ls -la
          echo "=== Coverage files ==="
          find . -name "coverage*" -type f 2>/dev/null | head -50
          echo "=== Test output files ==="
          find . -name "*test*.txt" -o -name "*test*.xml" -o -name "*test*.html" 2>/dev/null | head -50
          echo "=== Mutation files ==="
          find . -name "*mutation*" -o -name "*mutant*" -o -name "*pit-reports*" 2>/dev/null | head -50

      - name: Parse and summarize metrics
        if: always()
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os
          summary={}
          for lang in ['python','cpp','java','kotlin','go']:
          d=f'reports/{lang}'
          if os.path.isdir(d):
          files=os.listdir(d)
          summary[lang]={'files':files}
          with open('metrics_summary.json','w') as f:
          json.dump(summary,f,indent=2)
          with open('metrics_summary.md','w') as f:
          f.write('# Metrics summary\n\n')
          for k,v in summary.items():
          f.write(f'## {k}\n')
          for it in v['files'][:30]:
            f.write(f'- {it}\n')
          f.write('\n')
          print('Wrote metrics_summary.json and .md')
          PY

      - name: Upload consolidated metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pr-${{ github.event.inputs.pr_number }}-metrics-summary
          path: |
            reports
            metrics_summary.json
            metrics_summary.md
          retention-days: 30

      - name: Generate job summary
        if: always()
        run: |
          if [ -f "metrics_summary.md" ]; then
            cat metrics_summary.md >> $GITHUB_STEP_SUMMARY
          else
            echo "No metrics summary available" >> $GITHUB_STEP_SUMMARY
          fi
